{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "749b0ddf",
   "metadata": {},
   "source": [
    "<img align=\"left\" src = https://project.lsst.org/sites/default/files/Rubin-O-Logo_0.png width=250 style=\"padding: 10px\"> \n",
    "<b>CET Template Notebook</b> <br>\n",
    "Contact author(s): <i>Author Name</i> <br>\n",
    "Last verified to run: <i>yyyy-mm-dd</i> <br>\n",
    "LSST Science Piplines version: Weekly <i>yyyy_xx</i> <br>\n",
    "Container Size: <i>medium</i> <br>\n",
    "Targeted learning level: <i>beginner</i> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9cd09b-d5c4-4610-993b-711bdc9bd80e",
   "metadata": {},
   "source": [
    "_In this template, text in italics are examples or instructions that should be: (a) removed if it is not applicable to the notebook; or (b) replaced with text that is appropriate for the notebook. But bold or regular text should appear pretty much as-is in all CET notebooks. For more information, see the [CET's Guidelines for Tutorial Notebooks](https://confluence.lsstcorp.org/pages/viewpage.action?pageId=168857070)._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582ab507-a7ae-4024-95c9-38aabeb602a6",
   "metadata": {},
   "source": [
    "_While developing, use the following code cell to check that the code conforms to standards, but then delete the cell and \"Kernel --> Restart Kernel and Clear All Outputs\" before saving and committing._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acc79a4-8530-42d9-96e5-b7acb4397864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext pycodestyle_magic\n",
    "# %flake8_on\n",
    "# import logging\n",
    "# logging.getLogger(\"flake8\").setLevel(logging.FATAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482777d8-0a8d-432e-ba53-2da536700407",
   "metadata": {},
   "source": [
    "_The six cells below are considered the extended header of the notebook. The first four will be used, verbatim, to create the table of notebook metadata in the README.md file for the repository._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da1a210-d858-42fe-8591-570965b8be1a",
   "metadata": {},
   "source": [
    "**Description:** _Very brief description of notebook._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a0baf5-51ad-40ec-8991-060a7b27c289",
   "metadata": {},
   "source": [
    "**Skills:** _Brief list of skills to match the README.md file for the repository._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393da88f-7978-4920-aa4a-a9830df6eed9",
   "metadata": {},
   "source": [
    "**LSST Data Products:** _List the all of the types of LSST catalogs and images used._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c67fab9-136a-4adc-bb42-142b91ab69dd",
   "metadata": {},
   "source": [
    "**Packages:** _List the python packages used._ (_List the packages being taught first, e.g., afwDisplay for a notebook about displaying images. Then supporting packages, e.g., lsst.daf.butler for a notebook about displaying images. It is OK to leave out basic support packages like os or glob.)_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f72b27f",
   "metadata": {},
   "source": [
    "**Credit:**\n",
    "_E.g., \"Originally developed by\" or \"Based on notebooks developed by\" and then people's names, including journal article or software release citations if appropriate._\n",
    "Please consider acknowledging them if this notebook is used for the preparation of journal articles, software releases, or other notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e91cbf-ab7f-4e26-9276-b00299d6065e",
   "metadata": {},
   "source": [
    "**Get Support:**\n",
    "Find DP0-related documentation and resources at <a href=\"https://dp0-2.lsst.io\">dp0-2.lsst.io</a>. Questions are welcome as new topics in the <a href=\"https://community.lsst.org/c/support/dp0\">Support - Data Preview 0 Category</a> of the Rubin Community Forum. Rubin staff will respond to all questions posted there."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc73be0",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "_Provide a light narrative about this notebook, e.g., \"This notebook will teach the user...\"._\n",
    "\n",
    "_Cite or link to any external information or documentation, and cross-reference to other notebooks._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc36f107",
   "metadata": {},
   "source": [
    "### 1.1 Package Imports\n",
    "\n",
    "_All package imports should be done in the first code cell._\n",
    "\n",
    "_Provide explanation or external links to package documentation, where appropriate._\n",
    "\n",
    "_E.g., Numpy is a fundamental package for scientific computing with arrays in Python (<a href=\"https://numpy.org\">numpy.org</a>)._\n",
    "\n",
    "_Use code cell comments to describe the packages being imported._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddc1458",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# general python packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('tableau-colorblind10')\n",
    "\n",
    "# LSST package for TAP queries\n",
    "from lsst.rsp import get_tap_service, retrieve_query\n",
    "\n",
    "# LSST package for Butler queries\n",
    "import lsst.daf.butler as dafButler\n",
    "\n",
    "# LSST package for image display\n",
    "import lsst.afw.display as afwDisplay\n",
    "\n",
    "from matplotlib import colormaps\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c217adff-25ed-4fce-95e7-8aa04630f6cc",
   "metadata": {},
   "source": [
    "### 1.2 Define Functions and Parameters\n",
    "\n",
    "Import some functions from Pedro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d86162-8557-4f65-9813-ec46818466a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from scipy.interpolate import CubicSpline\n",
    "from scipy.optimize import leastsq\n",
    "#Constants\n",
    "\n",
    "A = [3.332, 1.862]\n",
    "B = [0.631, 1.218]\n",
    "C = [0.986, 0.238]\n",
    "\n",
    "#values taken from sbpy for convenience\n",
    "\n",
    "alpha_12 = np.deg2rad([7.5, 30., 60, 90, 120, 150])\n",
    "\n",
    "phi_1_sp = [7.5e-1, 3.3486016e-1, 1.3410560e-1, 5.1104756e-2, 2.1465687e-2, 3.6396989e-3]\n",
    "phi_1_derivs = [-1.9098593, -9.1328612e-2]\n",
    "\n",
    "phi_2_sp = [9.25e-1, 6.2884169e-1, 3.1755495e-1, 1.2716367e-1, 2.2373903e-2, 1.6505689e-4]\n",
    "phi_2_derivs = [-5.7295780e-1, -8.6573138e-8]\n",
    "\n",
    "alpha_3 = np.deg2rad([0.0, 0.3, 1., 2., 4., 8., 12., 20., 30.])\n",
    "\n",
    "phi_3_sp = [1., 8.3381185e-1, 5.7735424e-1, 4.2144772e-1, 2.3174230e-1, 1.0348178e-1, 6.1733473e-2, 1.6107006e-2, 0.]\n",
    "phi_3_derivs = [-1.0630097, 0]\n",
    "\n",
    "\n",
    "phi_1 = CubicSpline(alpha_12, phi_1_sp, bc_type=((1,phi_1_derivs[0]),(1,phi_1_derivs[1])))\n",
    "phi_2 = CubicSpline(alpha_12, phi_2_sp, bc_type=((1,phi_2_derivs[0]),(1,phi_2_derivs[1])))\n",
    "phi_3 = CubicSpline(alpha_3, phi_3_sp, bc_type=((1,phi_3_derivs[0]),(1,phi_3_derivs[1])))\n",
    "\n",
    "\n",
    "def HG_model(phase, params):\n",
    "    \"\"\"\n",
    "    Reference: Bowell et al. (1989)\n",
    "    This is the oldest 2 parameter model. \n",
    "    \"\"\"\n",
    "    sin_a = np.sin(phase)\n",
    "    tan_ah = np.tan(phase/2)\n",
    "    \n",
    "    W = np.exp(-90.56 * tan_ah * tan_ah)    \n",
    "    scale_sina = sin_a/(0.119 + 1.341*sin_a - 0.754*sin_a*sin_a)\n",
    "    \n",
    "    phi_1_S = 1 - C[0] * scale_sina\n",
    "    phi_2_S = 1 - C[1] * scale_sina\n",
    "    \n",
    "    phi_1_L = np.exp(-A[0] * np.power(tan_ah, B[0]))\n",
    "    phi_2_L = np.exp(-A[1] * np.power(tan_ah, B[1]))\n",
    "    \n",
    "    phi_1 = W * phi_1_S + (1-W) * phi_1_L\n",
    "    phi_2 = W * phi_2_S + (1-W) * phi_2_L\n",
    "    return params[0] - 2.5*np.log10((1-params[1])* phi_1 + (params[1]) * phi_2) \n",
    "\n",
    "\n",
    "\n",
    "def HG1G2_model(phase, params):\n",
    "    \"\"\"\n",
    "    Reference: Muinonen et al. (2010) https://ui.adsabs.harvard.edu/abs/2010Icar..209..542M/abstract\n",
    "    This is the 3 parameter model, which works best when you have a sufficiently long phaseangle coverage.\n",
    "    \"\"\"\n",
    "\n",
    "    tan_ah = np.tan(phase/2)\n",
    "\n",
    "    phi_1_ev = phi_1(phase)  \n",
    "    phi_2_ev = phi_2(phase)  \n",
    "    phi_3_ev = phi_3(phase)  \n",
    "\n",
    "    msk = phase < 7.5 * np.pi/180\n",
    "\n",
    "    phi_1_ev[msk] = 1-6*phase[msk]/np.pi \n",
    "    phi_2_ev[msk] = 1- 9 * phase[msk]/(5*np.pi)\n",
    "\n",
    "    phi_3_ev[phase > np.pi/6] = 0\n",
    "\n",
    "    return params[0] - 2.5 * np.log10(params[1] * phi_1_ev + params[2] * phi_2_ev + (1-params[1]-params[2]) * phi_3_ev)\n",
    "\n",
    "\n",
    "def HG12_model(phase, params): \n",
    "    \"\"\"\n",
    "    Reference:\n",
    "    Muinonen et al. (2010) https://ui.adsabs.harvard.edu/abs/2010Icar..209..542M/abstract\n",
    "    This is a simplified version of HG1G2. It's more useful when phaseangle coverage is shorter.\n",
    "    \"\"\"\n",
    "    if params[1] >= 0.2:\n",
    "        G1 = +0.9529*params[1] + 0.02162 \n",
    "        G2 = -0.6125*params[1] + 0.5572\n",
    "    else:\n",
    "        G1 = +0.7527*params[1] + 0.06164  \n",
    "        G2 = -0.9612*params[1] + 0.6270\n",
    "\n",
    "    return HG1G2_model(phase, [params[0], G1, G2])\n",
    "\n",
    "\n",
    "def chi2(params, mag, phase, mag_err, model):\n",
    "    pred = model(phase, params)\n",
    "    return (mag - pred)/mag_err\n",
    "\n",
    "\n",
    "def fit(mag, phase, sigma, model=HG12_model, params=[0.1]):\n",
    "    phase = np.deg2rad(phase)\n",
    "\n",
    "    sol = leastsq(chi2, [mag[0]] + params,  (mag, phase, sigma, model), full_output = True)\n",
    "\n",
    "    return sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdf1dd4-10b7-4c1f-8f4f-b4ab252822a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fit_models(mag, magSigma, phaseAngle, tdist, rdist, verbose=False):\n",
    "\n",
    "    # correct the mag to 1AU distance\n",
    "    dmag = -5. * np.log10(tdist*rdist)\n",
    "    mag = mag + dmag\n",
    "\n",
    "    #double check if this is needed\n",
    "    #phaseAngle = np.deg2rad(phaseAngle)\n",
    "\n",
    "    # now we'll fit using each one of the HG, HG12 and HG1G2 models and store these in a dictionary of dictionaries\n",
    "    solutions = {}\n",
    "\n",
    "    #Let's do HG first\n",
    "    sol_HG = fit(mag, phaseAngle, magSigma, model=HG_model)\n",
    "\n",
    "    solutions['HG'] = {}\n",
    "    # save np.nan values when the fit has not been converged\n",
    "    try:\n",
    "        solutions['HG']['chi2'] = np.sum(sol_HG[2]['fvec']**2)\n",
    "        solutions['HG']['H'] = sol_HG[0][0]\n",
    "        solutions['HG']['G'] = sol_HG[0][1]\n",
    "        solutions['HG']['H_err'] = np.sqrt(sol_HG[1][0,0])\n",
    "        solutions['HG']['G_err'] = np.sqrt(sol_HG[1][1,1])\n",
    "        solutions['HG']['cov'] = sol_HG[1]\n",
    "    except TypeError:\n",
    "        if verbose:\n",
    "            print('HG model is not converging')\n",
    "        solutions['HG']['chi2'] = np.nan\n",
    "        solutions['HG']['H'] = np.nan\n",
    "        solutions['HG']['G'] = np.nan\n",
    "        solutions['HG']['H_err'] = np.nan\n",
    "        solutions['HG']['G_err'] = np.nan\n",
    "        solutions['HG']['cov'] = np.nan\n",
    "            \n",
    "\n",
    "    # now HG12\n",
    "    sol_HG12 = fit(mag, phaseAngle, magSigma, model=HG12_model)\n",
    "\n",
    "    solutions['HG12'] = {}\n",
    "    # save np.nan values when the fit has not been converged\n",
    "    try:\n",
    "        solutions['HG12']['chi2'] = np.sum(sol_HG12[2]['fvec']**2)\n",
    "        solutions['HG12']['H'] = sol_HG12[0][0]\n",
    "        solutions['HG12']['G12'] = sol_HG12[0][1]\n",
    "        solutions['HG12']['H_err'] = np.sqrt(sol_HG12[1][0,0])\n",
    "        solutions['HG12']['G12_err'] = np.sqrt(sol_HG12[1][1,1])\n",
    "        solutions['HG12']['cov'] = sol_HG12[1]\n",
    "    except TypeError:\n",
    "        if verbose:\n",
    "            print('HG12 model is not converging')\n",
    "        solutions['HG12']['chi2'] = np.nan\n",
    "        solutions['HG12']['H'] = np.nan\n",
    "        solutions['HG12']['G12'] = np.nan\n",
    "        solutions['HG12']['H_err'] = np.nan\n",
    "        solutions['HG12']['G12_err'] = np.nan\n",
    "        solutions['HG12']['cov'] = np.nan\n",
    "\n",
    "    # finally, HG1G2 - note this returns an extra parameter\n",
    "\n",
    "    # now HG12, let's tell the code we need that extra parameter\n",
    "    sol_HG1G2 = fit(mag, phaseAngle, magSigma, model=HG1G2_model, params=[0.1, 0.1])\n",
    "    \n",
    "    solutions['HG1G2'] = {}\n",
    "    # save np.nan values when the fit has not been converged\n",
    "    try:\n",
    "        solutions['HG1G2']['chi2'] = np.sum(sol_HG1G2[2]['fvec']**2)\n",
    "        solutions['HG1G2']['H'] = sol_HG1G2[0][0]\n",
    "        solutions['HG1G2']['G1'] = sol_HG1G2[0][1]\n",
    "        solutions['HG1G2']['G2'] = sol_HG1G2[0][1]\n",
    "        solutions['HG1G2']['H_err'] = np.sqrt(sol_HG1G2[1][0,0])\n",
    "        solutions['HG1G2']['G1_err'] = np.sqrt(sol_HG1G2[1][1,1])\n",
    "        solutions['HG1G2']['G2_err'] = np.sqrt(sol_HG1G2[1][2,2])\n",
    "        solutions['HG1G2']['cov'] = sol_HG1G2[1]\n",
    "    except TypeError:\n",
    "        if verbose: \n",
    "            print('HG1G2 model is not converging')\n",
    "        solutions['HG1G2']['chi2'] = np.nan\n",
    "        solutions['HG1G2']['H'] = np.nan\n",
    "        solutions['HG1G2']['G1'] = np.nan\n",
    "        solutions['HG1G2']['G2'] = np.nan\n",
    "        solutions['HG1G2']['H_err'] = np.nan\n",
    "        solutions['HG1G2']['G1_err'] = np.nan\n",
    "        solutions['HG1G2']['G2_err'] = np.nan\n",
    "        solutions['HG1G2']['cov'] = np.nan\n",
    "    \n",
    "    \n",
    "    return solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec51ac0b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Querying the DP0.3 tables and fitting phase curves of SS objects\n",
    "\n",
    "Some notes:\n",
    "Definitions to help explain what we are doing in the tutorial:\n",
    "Model orbital properties from MPCORB:\n",
    "q = perihelion distance (au; do we need this?)\n",
    "mpcG = slope parameter G\n",
    "mpcH = absolute magnitude H\n",
    "For population studies, should we use the model parameters stored in MPCORB instead of re-doing the fitting? If yes, we should include mpcG and mpcH to the queries below.\n",
    "\n",
    "### 2.1 Create the Rubin TAP Service Client\n",
    "\n",
    "Get an instance of the TAP service, and assert that it exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b8cd59-1ba3-4eaa-846f-6478ed0c3cf5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "service = get_tap_service(\"ssotap\")\n",
    "assert service is not None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf968de5-ce59-41c9-88f0-83cd88bdc083",
   "metadata": {},
   "source": [
    "### 2.2 Querying the DP0.3 SSObject and MPCORB catalogs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171e087c-b314-48f7-8f22-6013115f2cb9",
   "metadata": {},
   "source": [
    "NOTE!!\n",
    "\n",
    "To ensure to have sufficient data points over a long enough phase angle baseline\n",
    "as well as to keep a reasonable run time for this tutorial,\n",
    "we select objects with number of objects > 3000 and arc > 3000 days. I came up with these numbers fter performing some run time tests. Especially, the fitting part takes long. \n",
    "\n",
    "For phase curve fitting, we need apparent magnitudes & uncertainties, phase angle topocentric (tdist) and heliocentric (rdist) distances & uncertainties (but they are 0; from SSSource). fitHG12 returns the absmag and phase coeff (G12) These will all be per band. \n",
    "\n",
    "In the ssObjectTable, the column G12 is correct in that the final table\n",
    "should contain the parameter G12, however, the existing version of the column\n",
    "actually contains parameter G (and therefore should be compared to the HG_model\n",
    "not HG12 model. The plan is to replace the contents of G12 column with actual G12\n",
    "fit parameters in the final version\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0c2c1c-9b6e-450f-8001-45617a43f5dc",
   "metadata": {},
   "source": [
    "What is the absolute magnitude? The measured magnitude (apparent magnitude) of a Solar System object depends on the incident light from the Sun, in addition to the distance to the observer (as is usual for sources outside the Solar System). So to convert from the apparent magnitude to the reduced magnitude, one factors in this reduction in flux, conventionally bringing both distances to 1 au so the conversion becomes a factor of -5log10 ( heliocentric distance * topocentric distance). There is also the question of the illumination angle, so that a higher phase angle means that a smaller fraction of the object's surface is being illuminated (I think that link @Yumi Choi sent earlier this week is the most accessible I've seen). The absolute magnitude is the magnitude at 1 au from the Sun, 1 au from the observer and at 0 phase angle (note this is an unphysical situation: an object will never satisfy these 3 conditions simultaneously). Typically then one fits the absolute magnitude with an assumed phase curve model (eg the HG or HG12 models). That Muinonen et al (2010) paper goes over in detail.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d59d020-7e09-4626-9aa8-287bc20187d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nobs_thrh = '3000' # Number of LSST observations\n",
    "arc_thrh = '3000' # Arc of LSST observations; units in days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9841c6de-f012-41e7-aae7-23da5c77e4e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Getting a table of columns for unique objects with number of observations > nobs_thrh and arc longer than arc_thrh\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    mpc.ssObjectId, mpc.q, sso.arc, sso.numObs, \n",
    "    sso.uH, sso.uHerr, sso.uG12, sso.uG12err, \n",
    "    sso.gH, sso.gHerr, sso.gG12, sso.gG12err, \n",
    "    sso.rH, sso.rHerr, sso.rG12, sso.rG12err, \n",
    "    sso.iH, sso.iHerr, sso.iG12, sso.iG12err, \n",
    "    sso.zH, sso.zHerr, sso.zG12, sso.zG12err, \n",
    "    sso.yH, sso.yHerr, sso.yG12, sso.yG12err\n",
    "FROM \n",
    "    dp03_catalogs.MPCORB as mpc \n",
    "INNER JOIN dp03_catalogs.SSObject as sso \n",
    "ON mpc.ssObjectId = sso.ssObjectId \n",
    "WHERE sso.numObs > {} AND sso.arc > {} ORDER by sso.ssObjectId \n",
    "\"\"\".format(nobs_thrh, arc_thrh)\n",
    "\n",
    "df_uniqueObj = service.search(query).to_table()\n",
    "df_uniqueObj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977dd781-f675-4ed4-89ac-07cb6042515e",
   "metadata": {},
   "source": [
    "### 2.3 Querying the DP0.3 DiaSource and SSSource catalogs\n",
    "\n",
    "Getting a table for time series data for unique objects with number of observations > nobs_thrh and arc longer than arc_thrh\n",
    "This query usually takes ~30 sec, but could run a bit longer when traffic is busy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb665e68-f274-4c50-9b82-4899b084c33a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT \n",
    "    dia.ssObjectId, dia.diaSourceId, dia.mag,\n",
    "    dia.magSigma, dia.filter, dia.midPointTai, \n",
    "    sss.phaseAngle, sss.topocentricDist, sss.heliocentricDist\n",
    "FROM \n",
    "    dp03_catalogs.DiaSource as dia\n",
    "INNER JOIN \n",
    "    dp03_catalogs.SSSource as sss\n",
    "ON \n",
    "    dia.diaSourceId = sss.diaSourceId\n",
    "WHERE \n",
    "    dia.ssObjectId \n",
    "    IN (\n",
    "        SELECT sso.ssObjectId\n",
    "        FROM dp03_catalogs.SSObject as sso \n",
    "        WHERE sso.numObs > {} AND sso.arc > {}\n",
    "        )\n",
    "ORDER by dia.ssObjectId \n",
    "\"\"\".format(nobs_thrh, arc_thrh)\n",
    "\n",
    "df_indivObs = service.search(query).to_table()\n",
    "df_indivObs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e366f714-8078-40a5-9eee-65639fa293ca",
   "metadata": {},
   "source": [
    "Double check if the number of unique objects in df_indivObs equals to that of df_uniqueObj."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077c9400-f3fe-422d-bb2b-7ad0f2587e3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert len(df_uniqueObj) == len(np.unique(df_indivObs['ssObjectId']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57f57e2-a386-46af-a527-73d397658b72",
   "metadata": {},
   "source": [
    "### 2.4 Fitting phase curve per filter per unique object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392ff14e-eca1-4677-8de8-4dae0e6811bc",
   "metadata": {},
   "source": [
    "Compute reduced magnitude for each observation and add it as a column to the df_indivObs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a387ad4-6057-4631-84fc-da9f99559b26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dmag = -5. * np.log10(df_indivObs['topocentricDist']*df_indivObs['heliocentricDist'])\n",
    "reduced_mag = df_indivObs['mag'] + dmag\n",
    "\n",
    "df_indivObs.add_column(reduced_mag, name='reducedMag')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7962fafc-0b53-4c72-81c6-8519da6217d5",
   "metadata": {},
   "source": [
    "#### 2.4.1 Possibly store some additional parameters characterizing the measurements \n",
    "This could be useful for later in section 3, exploring what measurements we can use that are in df_indivObs and storing a \"quality\" parameter for them in a new column of df_uniqObj. Experimentation is in the next cell only, and can be easily deleted if not useful.\n",
    "\n",
    "Some ideas to compare uncertainties to: \n",
    "- number of observations (done)\n",
    "- arc (done)\n",
    "- sso.zNdata (or other filters) = number of datapoints used to fit phase curve (per filter; perhaps less noisy than total number of obs)\n",
    "- Pick mean or median apparent mag photometric uncertainty for the best 68% of measurements? \n",
    "- mean or median reduced mag uncertainty for best 68% of measurements?\n",
    "- sso.MOID = minimum orbit intersection distance to earth (farther at fixed size means potentially it will stay faint always?) Pedro suggests this will not be a useful metric as it will change a lot and won't be included in 2nd DP0.3 release.\n",
    "- Pick some median dia.snr = signal to noise ratio at which the source was detected in difference image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649c25be-14b0-4459-ae11-a4e59cbabe64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "98becb52-7bd3-44d8-9b06-f00b9a419467",
   "metadata": {},
   "source": [
    "Fitting phase curve per filter per unique object using three different fitting functions (each model fit are run in turn inside the fit_models function). This part takes ~6 min for 269 unique objects unless we parallelize the code. Note that I selected the medium server size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5771b7ed-a488-47b5-9c19-91beae25843a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fitted_array = []\n",
    "\n",
    "for iobj in df_uniqueObj['ssObjectId']:\n",
    "    idx = df_indivObs['ssObjectId'] == iobj\n",
    "    df_tmp = df_indivObs[idx]\n",
    "    filts = np.unique(df_tmp['filter'])\n",
    "    for ifilt in filts:\n",
    "        idx_filt = df_tmp['filter'] == ifilt\n",
    "        nobs_ifilt = len(df_tmp[idx_filt])\n",
    "    \n",
    "        # number of observations needs to be greater than the number of fit parameter, which is 3.\n",
    "        if nobs_ifilt > 3:\n",
    "            x_fitted = fit_models(df_tmp['mag'][idx_filt], \n",
    "                                  df_tmp['magSigma'][idx_filt], \n",
    "                                  df_tmp['phaseAngle'][idx_filt],\n",
    "                                  df_tmp['topocentricDist'][idx_filt],  \n",
    "                                  df_tmp['heliocentricDist'][idx_filt],\n",
    "                    )\n",
    "            fitted_array.append([iobj, ifilt, x_fitted])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3a2828-febe-4036-8f5c-06120a014310",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame(fitted_array)\n",
    "results.columns=['ssObjectId', 'fname', 'fit_param']\n",
    "\n",
    "# show the contexts of the model fit return:\n",
    "print(x_fitted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57c8214-2e6b-4355-af8d-284527705faa",
   "metadata": {},
   "source": [
    "Converting the fit parameter dictionary to individual columns in a pandas dataframe makes it easy to read each parameters. But it also takes some time. It might be great if we can come up with a more efficient way of storing and accessing all the necessary columns for making plots and doing analysis in later parts of this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5cbf77-0299-4063-86f1-533bc42fca60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = results[['ssObjectId', 'fname']].join(pd.json_normalize(results.fit_param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8447c26c-0f37-464e-8577-401ec764134b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# here we plot the G vs H from the HG model fit (returned above in x_fitted) for the g, r, and i bands\n",
    "plt.figure(figsize=(18,5))\n",
    "\n",
    "plt.subplot(131)\n",
    "h = plt.hist2d(results[results.fname=='g']['HG.H'], results[results.fname=='g']['HG.G'], bins=100)\n",
    "plt.title('g-band')\n",
    "plt.xlabel('H')\n",
    "plt.ylabel('G')\n",
    "\n",
    "plt.subplot(132)\n",
    "h = plt.hist2d(results[results.fname=='r']['HG.H'], results[results.fname=='r']['HG.G'], bins=100)\n",
    "plt.title('r-band')\n",
    "plt.xlabel('H')\n",
    "plt.ylabel('G')\n",
    "\n",
    "plt.subplot(133)\n",
    "h = plt.hist2d(results[results.fname=='i']['HG.H'], results[results.fname=='i']['HG.G'], bins=100)\n",
    "plt.title('i-band')\n",
    "plt.xlabel('H')\n",
    "plt.ylabel('G')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3523f9a4-1773-4731-97c8-8d14c1487846",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot example phase curve for a single object\n",
    "sId = df_uniqueObj['ssObjectId'][0]\n",
    "df_tmp = df_indivObs[df_indivObs['ssObjectId'] == sId]\n",
    "\n",
    "for ifilt in filts:\n",
    "    idx = df_tmp['filter'] == ifilt\n",
    "    \n",
    "    plt.errorbar(df_tmp['phaseAngle'][idx], df_tmp['reducedMag'][idx], yerr=df_tmp['magSigma'][idx], fmt='o', label=ifilt)\n",
    "\n",
    "    phases = np.linspace(0,90,100)\n",
    "    HG_mag = HG_model(np.deg2rad(phases),\n",
    "                     [results[(results.ssObjectId == sId) & (results.fname == ifilt)]['HG.H'].values,\n",
    "                      results[(results.ssObjectId == sId) & (results.fname == ifilt)]['HG.G'].values])\n",
    "    # HG12_mag = HG12_model(np.deg2rad(phases), [x['HG12']['H'], x['HG12']['G12']])\n",
    "    # HG_mag = HG_model(np.deg2rad(phases), [x['HG']['H'], x['HG']['G']])\n",
    "    # HG1G2_mag = HG1G2_model(np.deg2rad(phases), [x['HG1G2']['H'], x['HG1G2']['G1'], x['HG1G2']['G2']])\n",
    "\n",
    "    plt.plot(phases, HG_mag, label ='HG 2-parameter model')\n",
    "    \n",
    "plt.xlim(df_tmp['phaseAngle'].min()-5, df_tmp['phaseAngle'].max()+5)\n",
    "plt.ylim(df_tmp['reducedMag'].max()+0.5, df_tmp['reducedMag'].min()-0.5)\n",
    "plt.xlabel('Phase Angle [deg]')\n",
    "plt.ylabel('Reduced magnitude [mag]')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')\n",
    "plt.title('ssObjectId = %d' % sId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b072f76-a90b-4a75-89ff-65cc00c8c1cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# experiment with plotting error ranges\n",
    "# df_uniqueObj contains the model params and errors\n",
    "# df_tmp is the table of obs for just the first object in df_indivObs\n",
    "\n",
    "# pick a source with lower S/N than the last cell, to explore uncertainty range\n",
    "x = 2\n",
    "sId = df_uniqueObj['ssObjectId'][x]\n",
    "df_tmp = df_indivObs[df_indivObs['ssObjectId'] == sId]\n",
    "\n",
    "# pick a filter with poor S/N to demonstrate fit uncertainty\n",
    "ifilt = 'u'\n",
    "idx = df_tmp['filter'] == ifilt\n",
    "\n",
    "\n",
    "plt.errorbar(df_tmp['phaseAngle'][idx], df_tmp['reducedMag'][idx], yerr=df_tmp['magSigma'][idx],\n",
    "             fmt='o', label=ifilt, zorder=10)\n",
    "\n",
    "\n",
    "# grab the corresponding model that is already in SSObject Table\n",
    "# (remarkably, one can add strings inside the header!):\n",
    "HG_mag_sso = HG_model(np.deg2rad(phases), [df_uniqueObj[ifilt+'H'][x], df_uniqueObj[ifilt+'G12'][x]])\n",
    "plt.plot(phases, HG_mag_sso, color='k',label ='HG model stored in SSO Table')\n",
    "\n",
    "\n",
    "# plot the uncertainty ranges:\n",
    "HG_mag_sso_Hup = HG_model(np.deg2rad(phases), [df_uniqueObj[ifilt+'H'][x]+df_uniqueObj[ifilt+'Herr'][x], \n",
    "                                              df_uniqueObj[ifilt+'G12'][x]])\n",
    "\n",
    "HG_mag_sso_Hlow = HG_model(np.deg2rad(phases), [df_uniqueObj[ifilt+'H'][x]-df_uniqueObj[ifilt+'Herr'][x], \n",
    "                                              df_uniqueObj[ifilt+'G12'][x]])\n",
    "\n",
    "HG_mag_sso_Gup = HG_model(np.deg2rad(phases), [df_uniqueObj[ifilt+'H'][x], \n",
    "                                              df_uniqueObj[ifilt+'G12'][x]+df_uniqueObj[ifilt+'G12err'][x]])\n",
    "\n",
    "HG_mag_sso_Glow = HG_model(np.deg2rad(phases), [df_uniqueObj[ifilt+'H'][x], \n",
    "                                              df_uniqueObj[ifilt+'G12'][x]-df_uniqueObj[ifilt+'G12err'][x]])\n",
    "\n",
    "\n",
    "# plot the bounds of uncertainty in model fit as regions. Illustrative to see the\n",
    "# parameter separately, perhaps consider taking max of each region at each phase angle \n",
    "# in final version.\n",
    "plt.fill_between(phases, HG_mag_sso_Hlow, HG_mag_sso_Hup, color='gray', alpha=.2,\n",
    "                 label='Model uncertainty in absolute mag H')\n",
    "plt.fill_between(phases, HG_mag_sso_Glow, HG_mag_sso_Gup, color='green', alpha=.2,\n",
    "                label='Model uncertainty in parameter G')\n",
    "\n",
    "\n",
    "plt.xlim(df_tmp['phaseAngle'][idx].min()-5, df_tmp['phaseAngle'][idx].max()+5)\n",
    "plt.ylim(df_tmp['reducedMag'][idx].max()+0.5, df_tmp['reducedMag'][idx].min()-0.5)\n",
    "plt.xlabel('Phase Angle [deg]')\n",
    "plt.ylabel('Reduced magnitude [mag]')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')\n",
    "plt.title('ssObjectId = %d' % sId)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df408bac-a77a-4997-b946-b8f12bda924c",
   "metadata": {},
   "source": [
    "## 3. Population study of measurements of the SS objects DP0.3 tables \n",
    "\n",
    "Now that we have demonstrated how to fit a phase curve to DP0.3 data, experimented with different models, and compared to the automated fits that are stored in the SSObject Table, we look at the population in aggregate: population study with the fit results (e.g., how the fit values differ due to number of observations, or for near/far or bright/faint objects)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ab0a46-f65a-4cde-a665-4231fa65d291",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# First, re-query for a table of columns for unique objects with number of observations and arc over larger\n",
    "# dynamic range than before, and add some extra criteria of use in assessing uncertainty. To decide: is\n",
    "# this second query is necessary, or should we adapt the earlier query and sub-sample it with \n",
    "# nobs_thrh and arc_thrh >3000, since the query takes a long time (~5 min).\n",
    "\n",
    "nobs_thrh = 50 \n",
    "arc_thrh = 100\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    mpc.ssObjectId, mpc.q, sso.arc, sso.numObs, \n",
    "    sso.uH, sso.uHerr, sso.uG12, sso.uG12err, \n",
    "    sso.gH, sso.gHerr, sso.gG12, sso.gG12err, \n",
    "    sso.rH, sso.rHerr, sso.rG12, sso.rG12err, \n",
    "    sso.iH, sso.iHerr, sso.iG12, sso.iG12err, \n",
    "    sso.zH, sso.zHerr, sso.zG12, sso.zG12err, \n",
    "    sso.yH, sso.yHerr, sso.yG12, sso.yG12err,\n",
    "    sso.uNdata, sso.gNdata, sso.rNdata, \n",
    "    sso.iNdata, sso.zNdata, sso.yNdata\n",
    "FROM \n",
    "    dp03_catalogs.MPCORB as mpc \n",
    "INNER JOIN dp03_catalogs.SSObject as sso \n",
    "ON mpc.ssObjectId = sso.ssObjectId \n",
    "WHERE sso.numObs > {} AND sso.arc > {} ORDER by sso.ssObjectId \n",
    "\"\"\".format(nobs_thrh, arc_thrh)\n",
    "\n",
    "df_uniqueObj2 = service.search(query).to_table()\n",
    "df_uniqueObj2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c071e963-ebb9-45f0-bdde-6c43269dc6b2",
   "metadata": {},
   "source": [
    "### 3.1 First exploration based on numObs and arc of LSST obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f572d01-6e33-4107-b125-0134ba141500",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# using df_uniqueObj, look at numObs as a parameter that can impact fit quality. can also do rNdata\n",
    "#where r can be ifilt which is the The number of data points used to fit the phase curve (r band; these would \n",
    "# need to be added to the query). Or, q perihelion distance\n",
    "#(is there also a peri-earth distance?) or arc (Arc of LSST observations)\n",
    "# other possibiltiites to match in the join from MPCORB: n (Mean daily motion in degrees per day),\n",
    "# incl (inclination from ecliptic), \n",
    "\n",
    "plt.plot(df_uniqueObj2['numObs'], df_uniqueObj2['iHerr'],'.',alpha=.1,label='i-band abs mag')\n",
    "plt.plot(df_uniqueObj2['numObs'], df_uniqueObj2['iG12err'],'.',alpha=.1, label='i-band phase angle')\n",
    "\n",
    "plt.xlabel('Number of LSST observations')\n",
    "plt.ylabel(' uncertainty in phase angle fit parameter')\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.plot(df_uniqueObj2['arc'], df_uniqueObj2['iHerr'],'.',alpha=.1,label='i-band abs mag')\n",
    "plt.plot(df_uniqueObj2['arc'], df_uniqueObj2['iG12err'],'.',alpha=.1, label='i-band phase angle')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('arc of LSST observations')\n",
    "plt.ylabel(' uncertainty in phase angle fit parameter')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e8f22e-96f1-4061-be95-b580eb3cd33e",
   "metadata": {},
   "source": [
    "## 3.2 Number of data used per band\n",
    "\n",
    "The above plots compare numObs (total) with model fits (per band) which may not be the ideal metric since as one can see from the plots in Section 2.4, the quality of phase curves can vary quite a bit between filters. Instead, we can look at the number of datapoints included in the phase curve modeling on a per filter basis (i.e. rNdata for the r-band). Below, we look at the distribution of the number of used observations in each filter for all SSObjects which in total have more than 100 numObs and arc (as per query above). One can see that generally, r and i bands produce the most data points for recovering phase curves, while u-band produces the fewest. In the second plot, one can see that the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcb70cb-7a97-4cd2-bffc-1c68a434e94f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# first plot histograms to see what the observations look like:\n",
    "\n",
    "plt.hist(df_uniqueObj2['rNdata'],bins=80,alpha=.8,label='r-band data')\n",
    "plt.hist(df_uniqueObj2['iNdata'],bins=100,alpha=.4,color='orange',label='i-band data')\n",
    "\n",
    "plt.hist(df_uniqueObj2['yNdata'],bins=100,alpha=.6,color='magenta',label='y-band data')\n",
    "plt.hist(df_uniqueObj2['zNdata'],bins=100,alpha=.7,color='r',label='z-band data')\n",
    "plt.hist(df_uniqueObj2['gNdata'],bins=100,alpha=.8,color='green',label='g-band data')\n",
    "plt.hist(df_uniqueObj2['uNdata'],bins=100,alpha=.9,color='blue',label='u-band data')\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.xlabel('Number of data points per filter')\n",
    "plt.ylabel('Number of sources')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# maybe this needs to be a density plot?\n",
    "plt.plot(df_uniqueObj2['rNdata'], 100*df_uniqueObj2['rHerr']/df_uniqueObj2['rH'],'.',alpha=.1,label='r-band abs mag')\n",
    "plt.plot(df_uniqueObj2['uNdata'], 100*df_uniqueObj2['uHerr']/df_uniqueObj2['uH'],'.',alpha=.1,label='u-band abs mag')\n",
    "plt.xlabel('Number of data points per filter')\n",
    "plt.ylabel('Fractional Uncertainty [%]')\n",
    "plt.legend()\n",
    "\n",
    "#plt.plot(df_uniqueObj2['rNdata'], df_uniqueObj2['rG12err'],'.',alpha=.1, label='r-band phase angle')\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5582914-20b4-4d37-be01-d7086c5ac652",
   "metadata": {},
   "source": [
    "## Junk Code Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd72e29-d068-436d-8a8d-01121a3d8dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is joining all 4 tables at once. It's convient b/c it returns a single table with all columns we need from the 4 tables, but takes longer than separting two queries \n",
    "\n",
    "# Getting a list of ssObjectID for sources with number of observations > 1000 and arc longer than 3000 days \n",
    "# to have sufficient phase angle coverage.\n",
    "# query0 = \"\"\"\n",
    "# SELECT \n",
    "#     mpc.ssObjectId, mpc.q, sso.arc, sso.numObs, \n",
    "#     sso.uH, sso.uHerr, sso.uG12, sso.uG12err, \n",
    "#     sso.gH, sso.gHerr, sso.gG12, sso.gG12err, \n",
    "#     sso.rH, sso.rHerr, sso.rG12, sso.rG12err, \n",
    "#     sso.iH, sso.iHerr, sso.iG12, sso.iG12err, \n",
    "#     sso.zH, sso.zHerr, sso.zG12, sso.zG12err, \n",
    "#     sso.yH, sso.yHerr, sso.yG12, sso.yG12err, \n",
    "#     sss.diaSourceId, dia.mag\n",
    "# FROM \n",
    "#     dp03_catalogs.MPCORB as mpc \n",
    "# INNER JOIN dp03_catalogs.SSObject as sso \n",
    "# ON mpc.ssObjectId = sso.ssObjectId \n",
    "# INNER JOIN dp03_catalogs.DiaSource as dia\n",
    "# ON sso.ssObjectId = dia.ssObjectId\n",
    "# INNER JOIN dp03_catalogs.SSSource as sss\n",
    "# ON dia.diaSourceId = sss.diaSourceId\n",
    "# WHERE sso.numObs > 2000 AND sso.arc > 3000 \n",
    "    \n",
    "# \"\"\"\n",
    "# df0 = service.search(query0).to_table()\n",
    "# df0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0d9211-1160-47fd-9a1e-70b814b827f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Object from Meg's notebook: -9223369546614897710\n",
    "#ssObjId = df0['ssObjectId'] \n",
    "\n",
    "# diaObjectId is the ID that links the individual measurements between DiaObject and SSSource,\n",
    "# so you have to match on this id for unique measurement matching. \n",
    "# To then match this object to MPCORB and SSObject, you have\n",
    "# to link on the SSObjectID (hwich is unique per solar system object)\n",
    "\n",
    "# query = \"SELECT dia.diaSourceId, sss.diaSourceId, dia.mag, \" + \\\n",
    "#         \"dia.magSigma, dia.filter, sss.phaseAngle, sss.topocentricDist, \" + \\\n",
    "#         \"sss.heliocentricDist, dia.midPointTai \" + \\\n",
    "#         \"FROM dp03_catalogs.DiaSource as dia \" + \\\n",
    "#         \"JOIN dp03_catalogs.SSSource as sss \" + \\\n",
    "#         \"ON dia.diaSourceId = sss.diaSourceId \" + \\\n",
    "#         \"WHERE dia.ssObjectId IN {} ORDER by sss.diaSourceId\".format(tuple(df0['ssObjectId']))\n",
    "\n",
    "\n",
    "# df = service.search(query).to_table()\n",
    "# df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
